{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "869f43d1-b593-4593-bfa1-74fc9acf6f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, Dict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision.ops import FeaturePyramidNetwork\n",
    "\n",
    "def setup_project_path() -> Path:\n",
    "    current = Path.cwd()\n",
    "    while current != current.parent and not (current / \"fpn\").exists():\n",
    "        current = current.parent\n",
    "    if not (current / \"fpn\").exists():\n",
    "        raise RuntimeError(\"Could not find project_root containing 'fpn' directory.\")\n",
    "    return current\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c1b8e07-9481-4999-9ad9-e1a64a17a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imwrite_unicode(path, img):\n",
    "    path = str(path)\n",
    "    ext = os.path.splitext(path)[1]\n",
    "    ok, buf = cv2.imencode(ext, img)\n",
    "    if not ok:\n",
    "        return False\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(buf.tobytes())\n",
    "    return True\n",
    "\n",
    "\n",
    "def imread_unicode(path, flags=cv2.IMREAD_COLOR):\n",
    "    try:\n",
    "        path = str(path)\n",
    "        with open(path, \"rb\") as f:\n",
    "            data = f.read()\n",
    "        img_array = np.frombuffer(data, np.uint8)\n",
    "        img = cv2.imdecode(img_array, flags)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(\"[imread_unicode ERROR]\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede4fad0-ff65-45eb-8d4e-26dea22cdde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d3fd48-e1ec-4f17-8422-c3e5d6825a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetFPN(nn.Module):\n",
    "    def __init__(self, num_classes: int = 4, backbone: str = \"resnet34\", pretrained: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        if backbone == \"resnet34\":\n",
    "            base = torchvision.models.resnet34(\n",
    "                weights=torchvision.models.ResNet34_Weights.DEFAULT if pretrained else None\n",
    "            )\n",
    "            in_channels_list = [64, 128, 256, 512]\n",
    "\n",
    "        elif backbone == \"resnet18\":\n",
    "            base = torchvision.models.resnet18(\n",
    "                weights=torchvision.models.ResNet18_Weights.DEFAULT if pretrained else None\n",
    "            )\n",
    "            in_channels_list = [64, 128, 256, 512]\n",
    "\n",
    "        elif backbone == \"resnet50\":\n",
    "            base = torchvision.models.resnet50(\n",
    "                weights=torchvision.models.ResNet50_Weights.DEFAULT if pretrained else None\n",
    "            )\n",
    "            in_channels_list = [256, 512, 1024, 2048]\n",
    "\n",
    "        elif backbone == \"resnext50\":\n",
    "            base = torchvision.models.resnext50_32x4d(\n",
    "                weights=torchvision.models.ResNeXt50_32X4D_Weights.DEFAULT if pretrained else None\n",
    "            )\n",
    "            in_channels_list = [256, 512, 1024, 2048]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone: {backbone}\")\n",
    "\n",
    "        self.stem = nn.Sequential(base.conv1, base.bn1, base.relu, base.maxpool)\n",
    "\n",
    "        self.layer1 = base.layer1  # C2\n",
    "        self.layer2 = base.layer2  # C3\n",
    "        self.layer3 = base.layer3  # C4\n",
    "        self.layer4 = base.layer4  # C5\n",
    "\n",
    "        self.fpn = FeaturePyramidNetwork(in_channels_list=in_channels_list, out_channels=256)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(256 * 4, 256, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 128, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, num_classes, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        x = self.stem(x)\n",
    "        c2 = self.layer1(x)\n",
    "        c3 = self.layer2(c2)\n",
    "        c4 = self.layer3(c3)\n",
    "        c5 = self.layer4(c4)\n",
    "\n",
    "        feats = self.fpn({\"c2\": c2, \"c3\": c3, \"c4\": c4, \"c5\": c5})\n",
    "\n",
    "        p2 = F.interpolate(feats[\"c2\"], size=(H, W), mode=\"bilinear\", align_corners=False)\n",
    "        p3 = F.interpolate(feats[\"c3\"], size=(H, W), mode=\"bilinear\", align_corners=False)\n",
    "        p4 = F.interpolate(feats[\"c4\"], size=(H, W), mode=\"bilinear\", align_corners=False)\n",
    "        p5 = F.interpolate(feats[\"c5\"], size=(H, W), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        fused = torch.cat([p2, p3, p4, p5], dim=1)\n",
    "        return self.head(fused)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23b21882-c4fe-4d77-9675-e734af8d16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagenet_normalize_chw(x: torch.Tensor) -> torch.Tensor:\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=x.device)[:, None, None]\n",
    "    std  = torch.tensor([0.229, 0.224, 0.225], device=x.device)[:, None, None]\n",
    "    return (x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bafb58d-ac6e-40b7-8202-fbaaabcd192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_saved_matches_backbone(weight_path: Path, backbone: str):\n",
    "    sd = torch.load(weight_path, map_location=\"cpu\")\n",
    "    has_conv3 = any(\".conv3.weight\" in k for k in sd.keys())\n",
    "\n",
    "    if backbone in (\"resnet18\", \"resnet34\"):\n",
    "        if has_conv3:\n",
    "            raise RuntimeError(\n",
    "                f\"[BACKBONE MISMATCH] backbone={backbone} expects BasicBlock, \"\n",
    "                f\"but Bottleneck ckpt saved: {weight_path}\"\n",
    "            )\n",
    "    elif backbone in (\"resnet50\", \"resnext50\"):\n",
    "        if not has_conv3:\n",
    "            raise RuntimeError(\n",
    "                f\"[BACKBONE MISMATCH] backbone={backbone} expects Bottleneck, \"\n",
    "                f\"but BasicBlock ckpt saved: {weight_path}\"\n",
    "            )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown backbone: {backbone}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "866639b8-8516-416c-b2c2-e0cce6de6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize_mask(mask: np.ndarray) -> np.ndarray:\n",
    "    palette = np.array([\n",
    "        [0,   0,   0  ],   # 0 background\n",
    "        [255, 0,   0  ],   # 1 cho\n",
    "        [0,   255, 0  ],   # 2 jung\n",
    "        [0,   0,   255],   # 3 jong\n",
    "    ], dtype=np.uint8)\n",
    "    return palette[np.clip(mask, 0, 3)]\n",
    "\n",
    "\n",
    "def overlay(img_rgb: np.ndarray, mask_rgb: np.ndarray, alpha: float = 0.45) -> np.ndarray:\n",
    "    out = (1 - alpha) * img_rgb.astype(np.float32) + alpha * mask_rgb.astype(np.float32)\n",
    "    return np.clip(out, 0, 255).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c0d1243-adb0-4fe9-97e0-0348d40ec4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hangul_char_to_type(ch: str) -> str:\n",
    "    if len(ch) != 1:\n",
    "        raise ValueError(\"Input must be a single character.\")\n",
    "\n",
    "    code = ord(ch)\n",
    "    if code < 0xAC00 or code > 0xD7A3:\n",
    "        raise ValueError(f\"Non-Hangul syllable: {ch}\")\n",
    "\n",
    "    s_index = code - 0xAC00\n",
    "    jong_index = s_index % 28\n",
    "    jung_index = (s_index // 28) % 21\n",
    "\n",
    "    has_jong = (jong_index != 0)\n",
    "\n",
    "    horizontal = {8, 12, 13, 17, 18}                 # ㅗ,ㅛ,ㅜ,ㅠ,ㅡ\n",
    "    vertical   = {0, 1, 2, 3, 4, 5, 6, 7, 20}        # ㅏ,ㅐ,ㅑ,ㅒ,ㅓ,ㅔ,ㅕ,ㅖ,ㅣ\n",
    "    complex_   = {9, 10, 11, 14, 15, 16, 19}         # ㅘ,ㅙ,ㅚ,ㅝ,ㅞ,ㅟ,ㅢ\n",
    "\n",
    "    if jung_index in horizontal:\n",
    "        shape = \"horizontal\"\n",
    "    elif jung_index in vertical:\n",
    "        shape = \"vertical\"\n",
    "    else:\n",
    "        shape = \"complex\"\n",
    "\n",
    "    return f\"{shape}_{'jong' if has_jong else 'no_jong'}\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-craft]",
   "language": "python",
   "name": "conda-env-.conda-craft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
