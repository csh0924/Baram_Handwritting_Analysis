{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8b3294b-ff2d-4285-b422-5c3783ae2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def setup_project_path():\n",
    "    current = Path.cwd()\n",
    "    while not (current / 'craft').exists():\n",
    "        current = current.parent\n",
    "    return current\n",
    "project_root = setup_project_path()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from craft.common import craft\n",
    "from craft.common import craft_utils\n",
    "from craft.common import file_utils\n",
    "from craft.common import imgproc\n",
    "from craft.common.craft import CRAFT\n",
    "from craft.common.refinenet import RefineNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "20f7205e-1a01-47f0-9cf5-7d807973d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imwrite_unicode(path, img):\n",
    "    ext = os.path.splitext(path)[1]\n",
    "    ok, buf = cv2.imencode(ext, img)\n",
    "    if not ok:\n",
    "        return False\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(buf.tobytes())\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f47cdcf-2dfc-4e45-9d90-13d0e14efdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyStateDict(state_dict):\n",
    "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
    "        start_idx = 1\n",
    "    else:\n",
    "        start_idx = 0\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = \".\".join(k.split(\".\")[start_idx:])\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5fd1749d-870b-4869-9027-0c9d208905ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_craft_model(\n",
    "    trained_model: str = \"weights/craft_mlt_25k.pth\",\n",
    "    use_cuda: bool = True,\n",
    "    use_refiner: bool = False,\n",
    "    refiner_model: str = \"weights/craft_refiner_CTW1500.pth\",\n",
    "):\n",
    "    \"\"\"\n",
    "    CRAFT / RefineNet 모델을 로드해서 반환.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    net : torch.nn.Module\n",
    "        CRAFT 모델 (eval 모드)\n",
    "    refine_net : torch.nn.Module or None\n",
    "        RefineNet 모델 (옵션, eval 모드)\n",
    "    use_cuda : bool\n",
    "        실제로 cuda를 사용하는지 여부\n",
    "    \"\"\"\n",
    "    if use_cuda and not torch.cuda.is_available():\n",
    "        print(\"[WARN] CUDA is not available, fallback to CPU.\")\n",
    "        use_cuda = False\n",
    "\n",
    "    net = CRAFT()  # initialize\n",
    "\n",
    "    print(f\"Loading CRAFT weights from checkpoint: {trained_model}\")\n",
    "    if use_cuda:\n",
    "        net.load_state_dict(copyStateDict(torch.load(trained_model)))\n",
    "    else:\n",
    "        net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=\"cpu\")))\n",
    "\n",
    "    if use_cuda:\n",
    "        net = net.cuda()\n",
    "        net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = False\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    refine_net = None\n",
    "    if use_refiner:     \n",
    "        refine_net = RefineNet()\n",
    "        print(f\"Loading Refiner weights from checkpoint: {refiner_model}\")\n",
    "\n",
    "        if use_cuda:\n",
    "            refine_net.load_state_dict(copyStateDict(torch.load(refiner_model)))\n",
    "            refine_net = refine_net.cuda()\n",
    "            refine_net = torch.nn.DataParallel(refine_net)\n",
    "        else:\n",
    "            refine_net.load_state_dict(\n",
    "                copyStateDict(torch.load(refiner_model, map_location=\"cpu\"))\n",
    "            )\n",
    "\n",
    "        refine_net.eval()\n",
    "\n",
    "    return net, refine_net, use_cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f76e9c1-a144-4779-a1b3-4757f12db6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text(\n",
    "    net,\n",
    "    image,\n",
    "    text_threshold: float = 0.7,\n",
    "    link_threshold: float = 0.4,\n",
    "    low_text: float = 0.4,\n",
    "    use_cuda: bool = True,\n",
    "    poly: bool = False,\n",
    "    refine_net=None,\n",
    "    canvas_size: int = 1280,\n",
    "    mag_ratio: float = 1.5,\n",
    "    show_time: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    단일 이미지에 대해 CRAFT 추론을 수행하고 결과를 반환.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    net : CRAFT model\n",
    "    image : np.ndarray (H, W, 3) 또는 PIL.Image\n",
    "    text_threshold : float\n",
    "    link_threshold : float\n",
    "    low_text : float\n",
    "    use_cuda : bool\n",
    "    poly : bool\n",
    "    refine_net : RefineNet or None\n",
    "    canvas_size : int\n",
    "    mag_ratio : float\n",
    "    show_time : bool\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    boxes : list\n",
    "        텍스트 영역 box 리스트 (사각형 기준)\n",
    "    polys : list\n",
    "        텍스트 영역 polygon 리스트\n",
    "    score_heatmap : np.ndarray\n",
    "        score_text, score_link를 시각화한 heatmap 이미지\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 이미지 타입 통일\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "\n",
    "    # resize\n",
    "    img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(\n",
    "        image, canvas_size, interpolation=cv2.INTER_LINEAR, mag_ratio=mag_ratio\n",
    "    )\n",
    "    ratio_h = ratio_w = 1 / target_ratio\n",
    "\n",
    "    # preprocessing\n",
    "    x = imgproc.normalizeMeanVariance(img_resized)\n",
    "    x = torch.from_numpy(x).permute(2, 0, 1)  # [h, w, c] -> [c, h, w]\n",
    "    x = Variable(x.unsqueeze(0))  # [c, h, w] -> [b, c, h, w]\n",
    "\n",
    "    if use_cuda:\n",
    "        x = x.cuda()\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        y, feature = net(x)\n",
    "\n",
    "    # score & link map\n",
    "    score_text = y[0, :, :, 0].cpu().data.numpy()\n",
    "    score_link = y[0, :, :, 1].cpu().data.numpy()\n",
    "\n",
    "    # refine link\n",
    "    if refine_net is not None:\n",
    "        with torch.no_grad():\n",
    "            y_refiner = refine_net(y, feature)\n",
    "        score_link = y_refiner[0, :, :, 0].cpu().data.numpy()\n",
    "\n",
    "    t0 = time.time() - t0\n",
    "    t1 = time.time()\n",
    "\n",
    "    # Post-processing\n",
    "    boxes, polys = craft_utils.getDetBoxes(\n",
    "        score_text, score_link, text_threshold, link_threshold, low_text, poly\n",
    "    )\n",
    "\n",
    "    # 좌표 원본 크기로 보정\n",
    "    boxes = craft_utils.adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
    "    polys = craft_utils.adjustResultCoordinates(polys, ratio_w, ratio_h)\n",
    "    for k in range(len(polys)):\n",
    "        if polys[k] is None:\n",
    "            polys[k] = boxes[k]\n",
    "\n",
    "    t1 = time.time() - t1\n",
    "\n",
    "    # heatmap 생성\n",
    "    render_img = score_text.copy()\n",
    "    render_img = np.hstack((render_img, score_link))\n",
    "    score_heatmap = imgproc.cvt2HeatmapImg(render_img)\n",
    "\n",
    "    if show_time:\n",
    "        print(\"infer/postproc time : {:.3f}/{:.3f}\".format(t0, t1))\n",
    "\n",
    "    return boxes, polys, score_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8034b23b-8896-4070-83d9-fbf8fc91ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_craft_on_folder(\n",
    "    net,\n",
    "    refine_net,\n",
    "    use_cuda: bool,\n",
    "    test_folder: str,\n",
    "    result_folder: str = \"./result\",\n",
    "    text_threshold: float = 0.7,\n",
    "    link_threshold: float = 0.4,\n",
    "    low_text: float = 0.4,\n",
    "    canvas_size: int = 1280,\n",
    "    mag_ratio: float = 1.5,\n",
    "    poly: bool = False,\n",
    "    show_time: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    폴더 내 이미지들에 대해 CRAFT 추론을 수행하고 결과 이미지/마스크 저장.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    net : CRAFT model\n",
    "    refine_net : RefineNet or None\n",
    "    use_cuda : bool\n",
    "    test_folder : str\n",
    "        입력 이미지 폴더\n",
    "    result_folder : str\n",
    "        결과 저장 폴더\n",
    "    이하 하이퍼파라미터는 detect_text()와 동일\n",
    "    \"\"\"\n",
    "    os.makedirs(result_folder, exist_ok=True)\n",
    "\n",
    "    image_list, _, _ = file_utils.get_files(test_folder)\n",
    "    if len(image_list) == 0:\n",
    "        print(f\"[WARN] No images found in folder: {test_folder}\")\n",
    "        return\n",
    "\n",
    "    t_start = time.time()\n",
    "\n",
    "    for k, image_path in enumerate(image_list):\n",
    "        print(\n",
    "            f\"Test image {k+1}/{len(image_list)}: {image_path}\",\n",
    "            end=\"\\r\",\n",
    "        )\n",
    "        image = imgproc.loadImage(image_path)\n",
    "\n",
    "        bboxes, polys, score_text = detect_text(\n",
    "            net=net,\n",
    "            image=image,\n",
    "            text_threshold=text_threshold,\n",
    "            link_threshold=link_threshold,\n",
    "            low_text=low_text,\n",
    "            use_cuda=use_cuda,\n",
    "            poly=poly,\n",
    "            refine_net=refine_net,\n",
    "            canvas_size=canvas_size,\n",
    "            mag_ratio=mag_ratio,\n",
    "            show_time=show_time,\n",
    "        )\n",
    "\n",
    "        # score text 저장\n",
    "        filename, file_ext = os.path.splitext(os.path.basename(image_path))\n",
    "        mask_file = os.path.join(result_folder, f\"res_{filename}_mask.jpg\")\n",
    "        ok = imwrite_unicode(mask_file, score_text)\n",
    "\n",
    "        # polygon 결과 저장\n",
    "        file_utils.saveResult(\n",
    "            image_path, image[:, :, ::-1], polys, dirname=result_folder\n",
    "        )\n",
    "\n",
    "    print(\"\\nElapsed time : {:.3f}s\".format(time.time() - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c3cd0730-eeca-4ebe-99f5-8b5ae075c0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] CUDA is not available, fallback to CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SehoonChoi\\.conda\\envs\\craft\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\SehoonChoi\\.conda\\envs\\craft\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CRAFT weights from checkpoint: D:\\Study\\학교강의\\4학년2학기\\캡스톤\\Baram_Handwritting_Analysis\\craft\\common\\weights\\craft_mlt_25k.pth\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "net, refine_net, use_cuda = load_craft_model(\n",
    "    trained_model = project_root/\"craft\"/\"common\"/\"weights\"/\"craft_mlt_25k.pth\", \n",
    "    use_cuda=True,           \n",
    "    use_refiner=False,        \n",
    "    refiner_model=project_root/\"craft\"/\"common\"/\"weights\"/\"craft_refiner_CTW1500.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2478ee8f-3f0b-4fbe-ae92-c35e4a7cb9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정 (원하는 대로 수정 가능)\n",
    "hp = {\n",
    "    \"text_threshold\": 0.7,\n",
    "    \"link_threshold\": 0.4,\n",
    "    \"low_text\": 0.4,\n",
    "    \"canvas_size\": 1280,\n",
    "    \"mag_ratio\": 1.5,\n",
    "    \"poly\": False,\n",
    "    \"show_time\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e0c4c10c-f3a7-4732-aeaa-c22d8c20ae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer/postproc time : 1.779/0.0032학기\\캡스톤\\Baram_Handwritting_Analysis\\craft\\images\\test2.png\n",
      "infer/postproc time : 1.789/0.0062학기\\캡스톤\\Baram_Handwritting_Analysis\\craft\\images\\test3.png\n",
      "infer/postproc time : 1.803/0.0052학기\\캡스톤\\Baram_Handwritting_Analysis\\craft\\images\\test4.png\n",
      "infer/postproc time : 1.885/0.0052학기\\캡스톤\\Baram_Handwritting_Analysis\\craft\\images\\test5.png\n",
      "\n",
      "Elapsed time : 7.476s\n"
     ]
    }
   ],
   "source": [
    "run_craft_on_folder(\n",
    "    net=net,\n",
    "    refine_net=refine_net,\n",
    "    use_cuda=use_cuda,\n",
    "    test_folder= project_root/\"craft\"/\"images\",       \n",
    "    result_folder=project_root/\"craft\"/\"images\", \n",
    "    **hp,                       \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-craft]",
   "language": "python",
   "name": "conda-env-.conda-craft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
