{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b66f71fb-422f-47f6-aff3-2465da493db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Tuple, List\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def setup_project_path():\n",
    "    current = Path.cwd()\n",
    "    while not (current / 'craft').exists():\n",
    "        current = current.parent\n",
    "    return current\n",
    "project_root = setup_project_path()\n",
    "sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d6f3fb8-b29a-42d0-8129-54f5faa5db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imwrite_unicode(path: str | Path, img: np.ndarray) -> bool:\n",
    "    path = str(path)\n",
    "    ext = os.path.splitext(path)[1]\n",
    "    ok, buf = cv2.imencode(ext, img)\n",
    "    if not ok:\n",
    "        return False\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(buf.tobytes())\n",
    "    return True\n",
    "\n",
    "\n",
    "def imread_unicode(path: str | Path, flags=cv2.IMREAD_GRAYSCALE) -> Optional[np.ndarray]:\n",
    "    path = str(path)\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            data = f.read()\n",
    "        arr = np.frombuffer(data, np.uint8)\n",
    "        return cv2.imdecode(arr, flags)\n",
    "    except Exception as e:\n",
    "        print(\"[imread_unicode ERROR]\", e, \"->\", path)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c05ab61e-8f81-49d6-9a85-30a04e4a647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_hangul(ch: str) -> Tuple[int, int, int]:\n",
    "    code = ord(ch)\n",
    "    if not (0xAC00 <= code <= 0xD7A3):\n",
    "        raise ValueError(\"한글 음절만 지원\")\n",
    "    s = code - 0xAC00\n",
    "    cho = s // (21 * 28)\n",
    "    jung = (s % (21 * 28)) // 28\n",
    "    jong = s % 28\n",
    "    return cho, jung, jong\n",
    "\n",
    "\n",
    "JUNG_HORIZ = {0,1,2,3,4,5,6,7,20}\n",
    "JUNG_VERT  = {8,12,13,17,18}\n",
    "JUNG_MIX   = {9,10,11,14,15,16,19}\n",
    "\n",
    "\n",
    "def vowel_type(jung_idx: int) -> str:\n",
    "    if jung_idx in JUNG_HORIZ: return \"horizontal\"\n",
    "    if jung_idx in JUNG_VERT:  return \"vertical\"\n",
    "    if jung_idx in JUNG_MIX:   return \"complex\"\n",
    "    raise ValueError(\"Unknown jung index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "905bafd5-02ba-4252-a246-f0d6f1133cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mask_255(path: Path) -> np.ndarray:\n",
    "    img = imread_unicode(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(path)\n",
    "    return (img > 0).astype(np.uint8) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eebf8dca-5faf-4939-9cd0-e08ec8667bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parts(ch: str, jamo_root: Path) -> Dict[str, Optional[np.ndarray]]:\n",
    "    cho, jung, jong = decompose_hangul(ch)\n",
    "    vtype = vowel_type(jung)\n",
    "    has_jong = (jong != 0)\n",
    "\n",
    "    base = \"jong\" if has_jong else \"nojong\"\n",
    "    folder = jamo_root / base / vtype\n",
    "\n",
    "    parts = {\n",
    "        \"cho\":  load_mask_255(folder / \"chosung\"  / f\"{cho}.png\"),\n",
    "        \"jung\": load_mask_255(folder / \"jungsung\" / f\"{jung}.png\"),\n",
    "        \"jong\": None\n",
    "    }\n",
    "\n",
    "    if has_jong:\n",
    "        parts[\"jong\"] = load_mask_255(folder / \"jongsung\" / f\"{jong}.png\")\n",
    "\n",
    "    return parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18c68bc-82f9-40fc-a851-661b425da6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_affine(rng, h, w, scale_range, shift_frac):\n",
    "    cx, cy = (w-1)/2, (h-1)/2\n",
    "    s = rng.uniform(*scale_range)\n",
    "    tx = rng.uniform(*shift_frac) * w\n",
    "    ty = rng.uniform(*shift_frac) * h\n",
    "    return np.array([\n",
    "        [s, 0, (1-s)*cx + tx],\n",
    "        [0, s, (1-s)*cy + ty]\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "def warp(mask, M):\n",
    "    h, w = mask.shape\n",
    "    out = cv2.warpAffine(\n",
    "        mask, M, (w, h),\n",
    "        flags=cv2.INTER_NEAREST,\n",
    "        borderMode=cv2.BORDER_CONSTANT,\n",
    "        borderValue=0\n",
    "    )\n",
    "    return (out > 0).astype(np.uint8) * 255\n",
    "\n",
    "def has_overlap(cho, jung, jong):\n",
    "    if np.any((cho>0) & (jung>0)): return True\n",
    "    if jong is not None:\n",
    "        if np.any((cho>0) & (jong>0)): return True\n",
    "        if np.any((jung>0) & (jong>0)): return True\n",
    "    return False\n",
    "\n",
    "def augment_parts_with_retry(parts, rng, scale_range, shift_frac, max_tries=50):\n",
    "    base_cho, base_jung, base_jong = parts[\"cho\"], parts[\"jung\"], parts[\"jong\"]\n",
    "    h, w = base_cho.shape\n",
    "\n",
    "    last = None\n",
    "\n",
    "    for _ in range(max_tries):\n",
    "        cho  = warp(base_cho,  make_affine(rng, h, w, scale_range, shift_frac))\n",
    "        jung = warp(base_jung, make_affine(rng, h, w, scale_range, shift_frac))\n",
    "        jong = warp(base_jong, make_affine(rng, h, w, scale_range, shift_frac)) if base_jong is not None else None\n",
    "\n",
    "        last = {\"cho\": cho, \"jung\": jung, \"jong\": jong}\n",
    "\n",
    "        if not has_overlap(cho, jung, jong):\n",
    "            return last\n",
    "\n",
    "    return last\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a87f62-4680-4527-95f2-ac320a9fe294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_label(parts):\n",
    "    label = np.zeros(parts[\"cho\"].shape, np.uint8)\n",
    "    label[parts[\"cho\"]>0] = 1\n",
    "    label[parts[\"jung\"]>0] = 2\n",
    "    if parts[\"jong\"] is not None:\n",
    "        label[parts[\"jong\"]>0] = 3\n",
    "    return label\n",
    "\n",
    "def to_visual(parts):\n",
    "    out = np.maximum(parts[\"cho\"], parts[\"jung\"])\n",
    "    if parts[\"jong\"] is not None:\n",
    "        out = np.maximum(out, parts[\"jong\"])\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eafcf7d-d4a7-4d9f-985a-3c24535a6d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(csv_path: Path):\n",
    "    rows = []\n",
    "    with open(csv_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for r in reader:\n",
    "            rows.append({\n",
    "                \"char\": r[\"char\"],\n",
    "                \"group6\": r[\"group6\"]\n",
    "            })\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1dcdb0b3-5fa0-4c37-851c-c080658b6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(\n",
    "    csv_path: Path,\n",
    "    jamo_root: Path,\n",
    "    out_root: Path,\n",
    "    variants_per_char=5,\n",
    "    scale_range=(0.92, 1.08),\n",
    "    shift_frac=(-0.03, 0.03),\n",
    "    seed=42,\n",
    "    max_tries=50,\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    img_root   = out_root / \"images\"\n",
    "    label_root = out_root / \"labels\"\n",
    "\n",
    "    groups = [\n",
    "        \"vertical_no_jong\", \"vertical_jong\",\n",
    "        \"horizontal_no_jong\", \"horizontal_jong\",\n",
    "        \"complex_no_jong\", \"complex_jong\"\n",
    "    ]\n",
    "\n",
    "    GROUP6_MAP = {\n",
    "        \"vert_no_jong\": \"vertical_no_jong\",\n",
    "        \"vert_jong\": \"vertical_jong\",\n",
    "        \"horiz_no_jong\": \"horizontal_no_jong\",\n",
    "        \"horiz_jong\": \"horizontal_jong\",\n",
    "        \"mix_no_jong\": \"complex_no_jong\",\n",
    "        \"mix_jong\": \"complex_jong\",\n",
    "\n",
    "        \"vertical_no_jong\": \"vertical_no_jong\",\n",
    "        \"vertical_jong\": \"vertical_jong\",\n",
    "        \"horizontal_no_jong\": \"horizontal_no_jong\",\n",
    "        \"horizontal_jong\": \"horizontal_jong\",\n",
    "        \"complex_no_jong\": \"complex_no_jong\",\n",
    "        \"complex_jong\": \"complex_jong\",\n",
    "    }\n",
    "\n",
    "    for g in groups:\n",
    "        (img_root / g).mkdir(parents=True, exist_ok=True)\n",
    "        (label_root / g).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    rows = read_csv(csv_path)\n",
    "    if len(rows) == 0:\n",
    "        raise ValueError(\"CSV is empty\")\n",
    "\n",
    "    for r in rows:\n",
    "        ch = r.get(\"char\")\n",
    "        if not ch or len(ch) != 1:\n",
    "            raise ValueError(f\"Invalid char in CSV row: {r}\")\n",
    "\n",
    "        raw_group = r.get(\"group6\")\n",
    "        if raw_group not in GROUP6_MAP:\n",
    "            raise ValueError(f\"Unknown group6 value: {raw_group}\")\n",
    "\n",
    "        group = GROUP6_MAP[raw_group]\n",
    "\n",
    "        parts_base = load_parts(ch, jamo_root)\n",
    "\n",
    "        stem = f\"{ch}_0x{ord(ch):04x}\"\n",
    "\n",
    "        for k in range(variants_per_char):\n",
    "            aug = augment_parts_with_retry(\n",
    "                parts_base,\n",
    "                rng=rng,\n",
    "                scale_range=scale_range,\n",
    "                shift_frac=shift_frac,\n",
    "                max_tries=max_tries\n",
    "            )\n",
    "\n",
    "            vis = to_visual(aug) \n",
    "            lab = to_label(aug)   \n",
    "\n",
    "            imwrite_unicode(img_root   / group / f\"{stem}_{k:02d}_흰꼬리수리.png\", vis)\n",
    "            imwrite_unicode(label_root / group / f\"{stem}_{k:02d}_흰꼬리수리.png\", lab)\n",
    "\n",
    "    print(\"Dataset generation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9c0a553-7d44-45a1-812a-2cf9f84c632d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generation complete.\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = Path(r\"D:\\Study\\학교강의\\4학년2학기\\캡스톤\\Baram_Handwritting_Analysis\\hangul_dataset\\korean_sample_jamo\")\n",
    "\n",
    "csv_path  = project_root / \"hangul_dataset\"/\"korean_char_frequence_analysis\"/\"hangul_syllable_frequency.csv\"\n",
    "out_root  = project_root / \"hangul_dataset\" / \"korean_generated\"\n",
    "\n",
    "generate_dataset(\n",
    "    csv_path=project_root / \"hangul_dataset\"/\"korean_char_frequence_analysis\"/\"hangul_syllable_frequency.csv\",\n",
    "    jamo_root=Path(r\"D:\\Study\\학교강의\\4학년2학기\\캡스톤\\Baram_Handwritting_Analysis\\hangul_dataset\\korean_sample_jamo\\korean_sample_jamo_흰꼬리수리\"),\n",
    "    out_root= out_root / \"korean_generated_흰꼬리수리\",\n",
    "    variants_per_char=3\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-craft]",
   "language": "python",
   "name": "conda-env-.conda-craft-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
